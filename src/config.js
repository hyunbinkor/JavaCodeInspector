import dotenv from 'dotenv';

dotenv.config();

export const config = {
  // LLM í†µí•© ì„¤ì •
  llm: {
    provider: process.env.LLM_PROVIDER || 'bedrock', // 'bedrock' ë˜ëŠ” 'ollama'
    
    // Bedrock ì„¤ì • (Claude, DeepSeek-R1 ì§€ì›)
    bedrock: {
      region: process.env.BEDROCK_REGION || 'us-east-1',
      modelId: process.env.BEDROCK_MODEL_ID || 'arn:aws:bedrock:us-east-1:484907498824:inference-profile/us.anthropic.claude-sonnet-4-20250514-v1:0',
      maxTokens: parseInt(process.env.BEDROCK_MAX_TOKENS) || 4000,
      temperature: parseFloat(process.env.BEDROCK_TEMPERATURE) || 0.1,
      // DeepSeek-R1 ëª¨ë¸ ìë™ ê°ì§€
      isDeepSeekR1: false // ìë™ìœ¼ë¡œ ì„¤ì •ë¨
    },
    
    // Ollama ì„¤ì • (ì•ˆì •ì„± ê°•í™”)
    ollama: {
      baseUrl: process.env.OLLAMA_BASE_URL || 'http://103.196.86.239:12942',
      model: process.env.OLLAMA_MODEL || 'qwen3-coder:30b',
      maxTokens: parseInt(process.env.OLLAMA_MAX_TOKENS) || 4000,
      temperature: parseFloat(process.env.OLLAMA_TEMPERATURE) || 0.1,
      timeout: parseInt(process.env.OLLAMA_TIMEOUT) || 180000, // 3ë¶„ íƒ€ì„ì•„ì›ƒ
      
      // ì•ˆì •ì„±ì„ ìœ„í•œ ì¶”ê°€ ì„¤ì •
      maxRequestSize: parseInt(process.env.OLLAMA_MAX_REQUEST_SIZE) || 8000,      // ìµœëŒ€ ìš”ì²­ í¬ê¸° (ë¬¸ì)
      chunkSize: parseInt(process.env.OLLAMA_CHUNK_SIZE) || 2000,                 // ì²­í¬ ë¶„í•  í¬ê¸°
      defaultTimeout: parseInt(process.env.OLLAMA_DEFAULT_TIMEOUT) || 90000,      // ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ (90ì´ˆ)
      backoffMultiplier: parseInt(process.env.OLLAMA_BACKOFF_MULTIPLIER) || 2000, // ì¬ì‹œë„ ê°„ê²© (ë°€ë¦¬ì´ˆ)
      
      // ECONNRESET ì˜¤ë¥˜ ëŒ€ì‘ ì„¤ì •
      connectionRetryDelay: parseInt(process.env.OLLAMA_CONNECTION_RETRY_DELAY) || 2000,  // ì—°ê²° ì¬ì‹œë„ ì§€ì—°
      maxConnectionRetries: parseInt(process.env.OLLAMA_MAX_CONNECTION_RETRIES) || 5,     // ìµœëŒ€ ì—°ê²° ì¬ì‹œë„
      enableKeepAlive: process.env.OLLAMA_ENABLE_KEEPALIVE !== 'false',                  // Keep-Alive í™œì„±í™”
      keepAliveTimeout: parseInt(process.env.OLLAMA_KEEPALIVE_TIMEOUT) || 30000          // Keep-Alive íƒ€ì„ì•„ì›ƒ
    },
    
    // ê³µí†µ ì„¤ì • (ì•ˆì •ì„± ê°•í™”)
    maxRetries: parseInt(process.env.LLM_MAX_RETRIES) || 2,
    maxContinuationAttempts: parseInt(process.env.LLM_MAX_CONTINUATION_ATTEMPTS) || 5,
    
    // ëŒ€ìš©ëŸ‰ ìš”ì²­ ì²˜ë¦¬ ì„¤ì •
    enableChunking: process.env.LLM_ENABLE_CHUNKING !== 'false',                 // ì²­í‚¹ í™œì„±í™”
    chunkOverlapSize: parseInt(process.env.LLM_CHUNK_OVERLAP_SIZE) || 100,       // ì²­í¬ ê²¹ì¹¨ í¬ê¸°
    maxChunksPerRequest: parseInt(process.env.LLM_MAX_CHUNKS_PER_REQUEST) || 5   // ìš”ì²­ë‹¹ ìµœëŒ€ ì²­í¬ ìˆ˜
  },
  
  // ê¸°ì¡´ ì„¤ì •ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±)  
  weaviate: {
    url: process.env.WEAVIATE_URL || 'http://localhost:8080',
    apiKey: process.env.WEAVIATE_API_KEY
  },
  
  app: {
    logLevel: process.env.LOG_LEVEL || 'info',
    batchSize: parseInt(process.env.BATCH_SIZE) || 10,
    
    // ì„±ëŠ¥ ìµœì í™” ì„¤ì •
    enableParallelProcessing: process.env.ENABLE_PARALLEL_PROCESSING !== 'false',
    maxParallelTasks: parseInt(process.env.MAX_PARALLEL_TASKS) || 3,
    
    // ì˜¤ë¥˜ ë³µêµ¬ ì„¤ì •
    enableGracefulDegradation: process.env.ENABLE_GRACEFUL_DEGRADATION !== 'false',
    fallbackToSimpleAnalysis: process.env.FALLBACK_TO_SIMPLE_ANALYSIS !== 'false'
  }
};

export const PATTERN_CATEGORIES = {
  RESOURCE_MANAGEMENT: 'resource_management',
  SECURITY_VULNERABILITY: 'security_vulnerability', 
  PERFORMANCE_ISSUE: 'performance_issue',
  FRAMEWORK_MISUSE: 'framework_misuse',
  BUSINESS_LOGIC_ERROR: 'business_logic_error',
  EXCEPTION_HANDLING: 'exception_handling',
  CONCURRENCY_ISSUE: 'concurrency_issue',
  ARCHITECTURE_VIOLATION: 'architecture_violation'
};

export const SEVERITY_LEVELS = {
  LOW: 'LOW',
  MEDIUM: 'MEDIUM', 
  HIGH: 'HIGH',
  CRITICAL: 'CRITICAL'
};

// Ollama ì „ìš© ìµœì í™” ì„¤ì •
export const OLLAMA_OPTIMIZATION = {
  // ìš”ì²­ í¬ê¸°ë³„ í† í° ì¡°ì •
  TOKEN_ADJUSTMENT: {
    SMALL_REQUEST: { threshold: 1000, tokens: 2000 },    // 1KB ì´í•˜
    MEDIUM_REQUEST: { threshold: 5000, tokens: 1500 },   // 5KB ì´í•˜  
    LARGE_REQUEST: { threshold: 10000, tokens: 1000 },   // 10KB ì´í•˜
    XLARGE_REQUEST: { threshold: 15000, tokens: 500 }    // 15KB ì´ìƒ
  },
  
  // ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
  BATCH_PROCESSING: {
    DEFAULT_BATCH_SIZE: 2,           // ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°
    MAX_BATCH_SIZE: 3,              // ìµœëŒ€ ë°°ì¹˜ í¬ê¸°
    MIN_BATCH_SIZE: 1,              // ìµœì†Œ ë°°ì¹˜ í¬ê¸°
    BATCH_TIMEOUT_MULTIPLIER: 1.5   // ë°°ì¹˜ íƒ€ì„ì•„ì›ƒ ë°°ìœ¨
  },
  
  // ì¬ì‹œë„ ì „ëµ
  RETRY_STRATEGY: {
    EXPONENTIAL_BACKOFF: true,       // ì§€ìˆ˜ ë°±ì˜¤í”„ ì‚¬ìš©
    MAX_BACKOFF_DELAY: 10000,       // ìµœëŒ€ ë°±ì˜¤í”„ ì§€ì—° (10ì´ˆ)
    JITTER_ENABLED: true,           // ì§€í„° í™œì„±í™”
    CONNECTION_ERROR_MULTIPLIER: 2   // ì—°ê²° ì˜¤ë¥˜ì‹œ ì§€ì—° ë°°ìˆ˜
  }
};

// í™˜ê²½ë³„ ì„¤ì • ê²€ì¦
export function validateConfig() {
  const errors = [];
  
  // LLM ì œê³µì ê²€ì¦
  if (!['ollama', 'bedrock'].includes(config.llm.provider)) {
    errors.push(`ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM ì œê³µì: ${config.llm.provider}`);
  }
  
  // Ollama ì„¤ì • ê²€ì¦
  if (config.llm.provider === 'ollama') {
    if (!config.llm.ollama.baseUrl) {
      errors.push('Ollama baseUrlì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }
    if (!config.llm.ollama.model) {
      errors.push('Ollama modelì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }
  }
  
  // Bedrock ì„¤ì • ê²€ì¦
  if (config.llm.provider === 'bedrock') {
    if (!config.llm.bedrock.modelId) {
      errors.push('Bedrock modelIdê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }
    if (!config.llm.bedrock.region) {
      errors.push('Bedrock regionì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }
  }
  
  return {
    isValid: errors.length === 0,
    errors: errors
  };
}

// ì„¤ì • ì´ˆê¸°í™” ë° ê²€ì¦
const validation = validateConfig();
if (!validation.isValid) {
  console.error('Config ê²€ì¦ ì‹¤íŒ¨:');
  validation.errors.forEach(error => console.error(`  - ${error}`));
  process.exit(1);
} else {
  console.log(`âœ… Config ê²€ì¦ ì™„ë£Œ - LLM ì œê³µì: ${config.llm.provider.toUpperCase()}`);
  
  if (config.llm.provider === 'ollama') {
    console.log(`ğŸ“¡ Ollama ì„œë²„: ${config.llm.ollama.baseUrl}`);
    console.log(`ğŸ¤– ëª¨ë¸: ${config.llm.ollama.model}`);
    console.log(`â±ï¸ íƒ€ì„ì•„ì›ƒ: ${config.llm.ollama.timeout}ms`);
    console.log(`ğŸ”„ ìµœëŒ€ ì¬ì‹œë„: ${config.llm.maxRetries}íšŒ`);
    
    if (config.llm.enableChunking) {
      console.log(`ğŸ“¦ ì²­í‚¹ í™œì„±í™” - ì²­í¬ í¬ê¸°: ${config.llm.ollama.chunkSize}ì`);
    }
  }
}